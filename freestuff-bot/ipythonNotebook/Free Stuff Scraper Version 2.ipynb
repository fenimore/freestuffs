{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports... Cool kids import on one line\n",
    "from lxml import html\n",
    "import requests, re, folium, webbrowser\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Stuff Object\n",
    "This program assumes that stuff ought to be free. Otherwise, why would I want it?\n",
    "## in Version 2 images work ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Stuff(object):\n",
    "    thing = \"\"\n",
    "    url = \"\"\n",
    "    location = \"\"\n",
    "    image = \"\"\n",
    "    #constructor the de-structor!!  \n",
    "    def __init__(self, thing, url, location, image):\n",
    "        self.thing = thing\n",
    "        self.url = 'http://montreal.craigslist.ca' + url\n",
    "        self.location = location\n",
    "        self.image = image #this isn't implemented yet\n",
    "\n",
    "    #the stringifing printer.... Python is so pretty\n",
    "    def __str__(self):\n",
    "        return \" what: %s \\n where: %s \\n link: %s \\n image: %s\" % (self.thing, self.location, self.url, self.image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Functions\n",
    "* So the first step is to find the user's city.\n",
    "* The second step is to gather the different lists of desirable/useful information (ie title, url, location, and image url)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location of User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup_place():\n",
    "    user_place = input(\"What major city are you near? (or, 'help') \")\n",
    "    if user_place == \"help\":\n",
    "        print(\"craigslist serves many major cities, and the peripheral neighborhoods, try something like 'montreal' or 'newyork'\")\n",
    "        user_place = input(\"What major city are you near? \")\n",
    "    return user_place "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup_page(user_place):\n",
    "    free_url = 'http://' + user_place +'.craigslist.com/search/zip'\n",
    "    try:\n",
    "        free_page = requests.get(free_url)\n",
    "        soup = BeautifulSoup(free_page.text)\n",
    "    except:\n",
    "        print(\"something when wrong\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location of Stuff and Url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_locations(user_place, soup):\n",
    "    free_locations = []\n",
    "    for span in soup.find_all(\"span\", class_=\"pnr\"):\n",
    "        loc_node = str(span.find('small'))\n",
    "        if loc_node == \"None\":\n",
    "            _loc = user_place +\", Somewhere\"\n",
    "        else:\n",
    "            _loc = loc_node.strip('<small ()</small>')\n",
    "            _loc = _loc + \", \" + user_place\n",
    "        #print(_loc)#\n",
    "        free_locations.append(_loc)\n",
    "    return free_locations\n",
    "\n",
    "def get_urls(soup):\n",
    "    free_urls = []\n",
    "    for row in soup.find_all(\"a\", class_=\"i\"):\n",
    "        _url = row['href']\n",
    "        free_urls.append(_url)\n",
    "    return free_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images and Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_images(soup):\n",
    "    free_images = []\n",
    "    for row in soup.find_all(\"a\", class_=\"i\"):\n",
    "        try:\n",
    "            _img = str(row['data-ids'])\n",
    "            _img = _img[2:]\n",
    "            _img = \"https://images.craigslist.org/\" + _img + \"_300x300.jpg\"\n",
    "        except:\n",
    "            _img = \"no image\"\n",
    "        free_images.append(_img)\n",
    "    return free_images\n",
    "\n",
    "def get_things(soup): # Thing is images\n",
    "    free_things = []\n",
    "    for node in soup.find_all(\"a\", class_=\"hdrlnk\"):\n",
    "        _thing = node.get_text()\n",
    "        free_things.append(_thing)\n",
    "    return free_things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**SO** what follows is to pass these *lists* into the constructor Stuff(blah), and wind up with a list of stuffs..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructor the De-Structor List Combobulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What major city are you near? (or, 'help') montreal\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Set Up\"\"\"\n",
    "place = setup_place() # user place\n",
    "soup = setup_page(place) # soup, needs the user place for request\n",
    "\"\"\"Construction\"\"\"\n",
    "locs = get_locations(place, soup) # locations, needs user place for fine tuning\n",
    "urls = get_urls(soup) # urls of stuff\n",
    "things = get_things(soup) # things of stuff\n",
    "images = get_images(soup) # get_images(soup) # WILL THIS EVERY WORK?\n",
    "\n",
    "\"\"\"Constructor Combobulator\"\"\"\n",
    "freestuffs = [Stuff(things[x], urls[x], locs[x], images[x]) for x in range(0,20)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " what: FREE Magazines by the pallet \n",
      " where: montreal, Somewhere \n",
      " link: http://montreal.craigslist.ca/zip/5041940898.html \n",
      " image: https://images.craigslist.org/00A0A_cWTj0ARWrS4_300x300.jpg\n"
     ]
    }
   ],
   "source": [
    "print(freestuffs[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## And then?\n",
    "Take this list of freestuffs and pass it into a map cruncher (ie. mappify) with the pretty pictures and all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
